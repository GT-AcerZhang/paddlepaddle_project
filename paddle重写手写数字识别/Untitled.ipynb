{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import paddle.fluid.dygraph as dygraph\n",
    "from paddle.fluid.dygraph.nn import Linear,Conv2D,Pool2D\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据存放在mnist.json.gz文件中\n",
    "### 数据类型：\n",
    "- train_val,dev_val,test_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#输出内容看看\\na = load_data()\\nt = 0\\nfor id,img in enumerate(a()):\\n    x,y = img\\n    t = t+1\\n    print(x.shape[0],x.shape[1],x.shape[2],x.shape[3])#打印一张图片维度\\nprint(t)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取数据，处理数据,定义数据处理器\n",
    "def load_model_data(model = \"train\"):\n",
    "    data_file = \"mnist.json.gz\"\n",
    "    data = json.load(gzip.open(data_file))\n",
    "    train_set,dev_set,test_set = data\n",
    "    \n",
    "    if model ==\"train\":\n",
    "        return train_set\n",
    "    elif model == \"dev\":\n",
    "        return dev_set\n",
    "    elif model == \"test\":\n",
    "        return test_set\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def load_data(model=\"train\"):\n",
    "    data_set = load_model_data(model)\n",
    "    #将标签和数据分别读取\n",
    "    imgs,label = np.array(data_set[0]),np.array(data_set[1])\n",
    "    #print(imgs.shape[1],label.shape[0])\n",
    "    #得到数据集id号\n",
    "    imgs_ids = [imgs_id for imgs_id,_ in enumerate(imgs)]\n",
    "    print(len(imgs_ids))\n",
    "    #将数据集打乱\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(imgs_ids)\n",
    "    #print(train_id)\n",
    "    #划分为多个mini_batch\n",
    "    batch_size = 100\n",
    "    #图片高度和宽度\n",
    "    img_h = 28\n",
    "    img_w = 28\n",
    "    def data_generator():\n",
    "        img_lists = []\n",
    "        label_lists = []\n",
    "        for imgs_id in imgs_ids:\n",
    "            img_list = np.reshape(imgs[imgs_id],[1,img_h,img_w]).astype(np.float32)\n",
    "            img_lists.append(img_list)#将一张图片像素存到list中\n",
    "            label_list = np.reshape(label[imgs_id],[1]).astype(np.int64)\n",
    "            label_lists.append(label_list)#将同一张图片标签存到list中\n",
    "            if len(img_lists) == (batch_size):\n",
    "                yield np.array(img_lists),np.array(label_lists)\n",
    "                #清除列表\n",
    "                img_lists = []\n",
    "                label_lists = []\n",
    "                \n",
    "        #将剩下的不到batch_size张的图片存成一组\n",
    "        if len(img_lists) > 0 :\n",
    "            yield np.array(img_lists),np.array(label_lists)\n",
    "    return data_generator\n",
    "#获取数据\n",
    "data = load_data(\"train\")\n",
    "\"\"\"\n",
    "#输出内容看看\n",
    "a = load_data()\n",
    "t = 0\n",
    "for id,img in enumerate(a()):\n",
    "    x,y = img\n",
    "    t = t+1\n",
    "    print(x.shape[0],x.shape[1],x.shape[2],x.shape[3])#打印一张图片维度\n",
    "print(t)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义网络结构\n",
    "class MNIST(fluid.dygraph.Layer):\n",
    "    def __init__(self):\n",
    "        super(MNIST,self).__init__()\n",
    "        #定义一层卷积层,输入图像为单通道，滤波器个数为5,滤波器大小5*5，步长1，填充p=2 \n",
    "        #输入为（batch,1*28*28）输出为（batch,5*28*28）\n",
    "        self.conv1 = Conv2D(num_channels = 1,num_filters = 5,filter_size=5,stride=1,padding=2,act = 'relu')\n",
    "        #定义一层池化网络，池化核大小为2*2，步长为2，最大池化\n",
    "        #输入为(5*28*28),输出为(5*14*14)\n",
    "        self.pool1 = Pool2D(pool_size = 2,pool_stride = 2,pool_type = 'max')\n",
    "        #定义一层卷积层,输入图像通道为5，滤波器个数为10,滤波器大小5*5，步长1，填充p=2 \n",
    "        #输入为（5*14*14）输出为（10*14*14）\n",
    "        self.conv2 = Conv2D(num_channels = 5,num_filters = 10,filter_size=5,stride=1,padding=2,act = 'relu')\n",
    "        #定义一层池化层\n",
    "        #输入为（10*14*14），输出为（batch,10*7*7）\n",
    "        self.pool2 = Pool2D(pool_size = 2,pool_stride = 2,pool_type = 'max')\n",
    "        #定义全连接层\n",
    "        self.fc = Linear(input_dim = 490,output_dim = 10,act = 'softmax')\n",
    "        \n",
    "    \n",
    "    def forward(self,inputs,label=None):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        #降维，传入全链接层\n",
    "        x = fluid.layers.reshape(x,[x.shape[0],490])\n",
    "        x = self.fc(x)\n",
    "        if label is not None:\n",
    "            acc = fluid.layers.accuracy(input = x,label=label)\n",
    "            return x,acc\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_id:0,batch_id:0,acc_avg:[0.15],loss_avg:[2.4733481]\n",
      "epoch_id:0,batch_id:200,acc_avg:[0.97],loss_avg:[0.09140906]\n",
      "epoch_id:0,batch_id:400,acc_avg:[0.96],loss_avg:[0.10556836]\n",
      "epoch_id:1,batch_id:0,acc_avg:[0.94],loss_avg:[0.18825608]\n",
      "epoch_id:1,batch_id:200,acc_avg:[0.96],loss_avg:[0.06586015]\n",
      "epoch_id:1,batch_id:400,acc_avg:[0.97],loss_avg:[0.07594597]\n",
      "epoch_id:2,batch_id:0,acc_avg:[0.97],loss_avg:[0.1232655]\n",
      "epoch_id:2,batch_id:200,acc_avg:[0.98],loss_avg:[0.0294485]\n",
      "epoch_id:2,batch_id:400,acc_avg:[0.99],loss_avg:[0.0513093]\n",
      "epoch_id:3,batch_id:0,acc_avg:[0.97],loss_avg:[0.05202278]\n",
      "epoch_id:3,batch_id:200,acc_avg:[0.99],loss_avg:[0.02579196]\n",
      "epoch_id:3,batch_id:400,acc_avg:[0.99],loss_avg:[0.03892378]\n",
      "epoch_id:4,batch_id:0,acc_avg:[1.],loss_avg:[0.02055982]\n",
      "epoch_id:4,batch_id:200,acc_avg:[0.99],loss_avg:[0.02075215]\n",
      "epoch_id:4,batch_id:400,acc_avg:[0.99],loss_avg:[0.02141345]\n"
     ]
    }
   ],
   "source": [
    "#训练,并保存模型，需要同时保存模型参数和优化器参数\n",
    "#是否使用gpu\n",
    "use_gpu = True\n",
    "place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\n",
    "with fluid.dygraph.guard(place):\n",
    "    \n",
    "\n",
    "    #设置轮数，batch_size大小\n",
    "    EPOCH_NUM = 5\n",
    "    batch_size = 100\n",
    "    #运行模型\n",
    "    model = MNIST()\n",
    "    model.train()\n",
    "    #定义优化器及其参数\n",
    "    \n",
    "    total_steps = EPOCH_NUM*(50000//batch_size+1)\n",
    "    lr = fluid.dygraph.PolynomialDecay(0.01,total_steps,0.001)\n",
    "    optimizer = fluid.optimizer.Adam(learning_rate=lr,parameter_list = model.parameters())\n",
    "\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "\n",
    "        for batch_id,batch_data in enumerate(data()):\n",
    "            #将数据转化为tensor类型\n",
    "            batch_imgs,label = batch_data\n",
    "            batch_imgs = dygraph.to_variable(batch_imgs)\n",
    "            label = dygraph.to_variable(label)\n",
    "            #前向传播\n",
    "            predect,acc = model(batch_imgs,label)\n",
    "            acc_avg = fluid.layers.mean(acc)\n",
    "            #计算损失\n",
    "            loss = fluid.layers.cross_entropy(predect,label)\n",
    "            loss_avg = fluid.layers.mean(loss)\n",
    "\n",
    "            #计算梯度\n",
    "            loss_avg.backward()\n",
    "            optimizer.minimize(loss_avg)\n",
    "            #清除梯度\n",
    "            model.clear_gradients()\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch_id:{},batch_id:{},acc_avg:{},loss_avg:{}\".format(epoch_id,batch_id,acc_avg.numpy(),loss_avg.numpy()))\n",
    "        \n",
    "        #保存模型\n",
    "        fluid.save_dygraph(model.state_dict(),\"./checkpoint/mnist_epoch{}\".format(epoch_id))\n",
    "        fluid.save_dygraph(optimizer.state_dict(),\"./checkpoint/mnist_epoch{}\".format(epoch_id))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_id:0,batch_id:0,acc_avg:[0.97],loss_avg:[0.05202278]\n",
      "epoch_id:0,batch_id:200,acc_avg:[0.99],loss_avg:[0.02064578]\n",
      "epoch_id:0,batch_id:400,acc_avg:[0.99],loss_avg:[0.03668122]\n",
      "epoch_id:1,batch_id:0,acc_avg:[1.],loss_avg:[0.02189492]\n",
      "epoch_id:1,batch_id:200,acc_avg:[1.],loss_avg:[0.01915164]\n",
      "epoch_id:1,batch_id:400,acc_avg:[0.99],loss_avg:[0.0207562]\n",
      "epoch_id:2,batch_id:0,acc_avg:[1.],loss_avg:[0.01628922]\n",
      "epoch_id:2,batch_id:200,acc_avg:[1.],loss_avg:[0.00458259]\n",
      "epoch_id:2,batch_id:400,acc_avg:[0.99],loss_avg:[0.01856178]\n",
      "epoch_id:3,batch_id:0,acc_avg:[1.],loss_avg:[0.01128377]\n",
      "epoch_id:3,batch_id:200,acc_avg:[1.],loss_avg:[0.00442235]\n",
      "epoch_id:3,batch_id:400,acc_avg:[0.99],loss_avg:[0.01655294]\n",
      "epoch_id:4,batch_id:0,acc_avg:[1.],loss_avg:[0.00945551]\n",
      "epoch_id:4,batch_id:200,acc_avg:[1.],loss_avg:[0.00442926]\n",
      "epoch_id:4,batch_id:400,acc_avg:[1.],loss_avg:[0.01471058]\n"
     ]
    }
   ],
   "source": [
    "#恢复训练\n",
    "#是否使用gpu\n",
    "parame_path = \"./checkpoint/mnist_epoch2\"\n",
    "use_gpu = True\n",
    "place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\n",
    "with fluid.dygraph.guard(place):\n",
    "    #恢复训练的参数\n",
    "    model_params,opt_dict = fluid.load_dygraph(parame_path)\n",
    "\n",
    "    #设置轮数，batch_size大小\n",
    "    EPOCH_NUM = 5\n",
    "    batch_size = 100\n",
    "    #运行模型\n",
    "    model = MNIST()\n",
    "    model.load_dict(model_params)\n",
    "    \n",
    "    total_steps = EPOCH_NUM*(50000//batch_size+1)\n",
    "    lr = fluid.dygraph.PolynomialDecay(0.01,total_steps,0.001)\n",
    "    optimizer = fluid.optimizer.Adam(learning_rate=lr,parameter_list = model.parameters())\n",
    "    optimizer.set_dict(opt_dict)#恢复优化器及其参数\n",
    "\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "\n",
    "        for batch_id,batch_data in enumerate(data()):\n",
    "            #将数据转化为tensor类型\n",
    "            batch_imgs,label = batch_data\n",
    "            batch_imgs = dygraph.to_variable(batch_imgs)\n",
    "            label = dygraph.to_variable(label)\n",
    "            #前向传播\n",
    "            predect,acc = model(batch_imgs,label)\n",
    "            acc_avg = fluid.layers.mean(acc)\n",
    "            #计算损失\n",
    "            loss = fluid.layers.cross_entropy(predect,label)\n",
    "            loss_avg = fluid.layers.mean(loss)\n",
    "\n",
    "            #计算梯度\n",
    "            loss_avg.backward()\n",
    "            optimizer.minimize(loss_avg)\n",
    "            #清除梯度\n",
    "            model.clear_gradients()\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch_id:{},batch_id:{},acc_avg:{},loss_avg:{}\".format(epoch_id,batch_id,acc_avg.numpy(),loss_avg.numpy()))\n",
    "        \n",
    "        #保存模型\n",
    "        fluid.save_dygraph(model.state_dict(),\"./checkpoint/mnist_epoch{}\".format(epoch_id))\n",
    "        fluid.save_dygraph(optimizer.state_dict(),\"./checkpoint/mnist_epoch{}\".format(epoch_id))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
